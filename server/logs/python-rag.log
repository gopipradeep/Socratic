{"@timestamp": "2026-01-13T06:12:01.613Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-13T06:13:20.645Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-13T06:13:28.638Z", "log.level": "warning", "log.logger": "huggingface_hub.file_download", "log.origin.file.line": 1729, "message": "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-13T06:16:59.064Z", "log.level": "warning", "log.logger": "huggingface_hub.utils._http", "log.origin.file.line": 319, "message": "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 418d364d-5d93-40a0-8500-596f1ca3b482)')' thrown while requesting HEAD https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1/resolve/main/tokenizer_config.json", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-13T06:16:59.064Z", "log.level": "warning", "log.logger": "huggingface_hub.utils._http", "log.origin.file.line": 328, "message": "Retrying in 1s [Retry 1/5].", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-13T06:17:04.528Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-13T06:17:04.558Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-13T06:17:04.560Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-13T06:17:16.573Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:04:04.437Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:04:17.521Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:04:28.181Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:04:28.189Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:04:28.190Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:04:29.231Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:25:52.806Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:26:02.620Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:26:12.950Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:26:12.958Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:26:12.959Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:26:14.099Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:31:21.422Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:31:26.619Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:31:32.919Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:31:32.925Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:31:32.926Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:31:33.761Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:42:22.713Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:42:29.607Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:42:40.069Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:42:40.076Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:42:40.078Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T03:42:42.870Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:02:50.875Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:03:00.710Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:03:08.864Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:03:08.873Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:03:08.875Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:03:09.799Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:08:40.442Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:08:47.279Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:08:52.373Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:08:52.380Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:08:52.381Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:08:53.168Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:24:47.185Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:24:52.661Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:24:58.434Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:24:58.436Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:24:58.436Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:24:59.224Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:47:40.643Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:47:49.545Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:47:55.311Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:47:55.320Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:47:55.323Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:47:56.420Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:57:23.327Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:57:27.745Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:57:34.246Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:57:34.248Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:57:34.250Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:57:35.208Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:59:18.798Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:59:23.293Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:59:29.037Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:59:29.041Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:59:29.042Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:59:29.843Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:59:54.999Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 113, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:59:55.008Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 122, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:59:55.010Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 27, "message": "Initializing VectorDBService...", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:59:55.011Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 28, "message": "  Qdrant Host: localhost, Port: 2003, URL: None", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:59:55.011Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 29, "message": "  Collection: my_qdrant_rag_collection", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:59:55.012Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 30, "message": "  Query Embedding Model: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:59:55.012Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 35, "message": "  Service expects Vector Dim for Qdrant collection: 1024 (from document model config)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:59:55.032Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 54, "message": "  Loading query embedding model: 'mixedbread-ai/mxbai-embed-large-v1'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T04:59:55.033Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:00:01.466Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:00:01.478Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:00:01.479Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 57, "message": "  Query model loaded. Output dimension: 1024", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:00:01.480Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 71, "message": "  Query model output dimension (1024) matches Qdrant collection dimension (1024).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:00:01.653Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 133, "message": "Collection 'my_qdrant_rag_collection' not found. Attempting to create...", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:00:01.654Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 82, "message": "Attempting to (re)create collection 'my_qdrant_rag_collection' with vector size 1024.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:00:02.263Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 91, "message": "Collection 'my_qdrant_rag_collection' (re)created successfully.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:00:02.269Z", "log.level": "critical", "log.logger": "neo4j_handler", "log.origin.file.line": 34, "message": "Failed to initialize Neo4j driver: No module named 'neo4j._sync.io._bolt3'", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\neo4j_handler.py\", line 27, in init_driver\n    _neo4j_driver.verify_connectivity()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1007, in verify_connectivity\n    self._get_server_info(session_config)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1218, in _get_server_info\n    return session._get_server_info()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 172, in _get_server_info\n    self._connect(READ_ACCESS, liveness_check_timeout=0)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 130, in _connect\n    super()._connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py\", line 178, in _connect\n    self._connection = self._pool.acquire(**acquire_kwargs_)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 528, in acquire\n    return self._acquire(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 315, in _acquire\n    return connection_creator()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 165, in connection_creator\n    connection = self.opener(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 502, in opener\n    return Bolt.open(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 400, in open\n    BoltSocket.connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 694, in connect\n    return BoltSocket._handshake(s, resolved_address, deadline)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 590, in _handshake\n    handshake = cls.Bolt.get_handshake()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 343, in get_handshake\n    supported_versions = sorted(cls.protocol_handlers().keys(), reverse=True)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 272, in protocol_handlers\n    from ._bolt3 import Bolt3\nModuleNotFoundError: No module named 'neo4j._sync.io._bolt3'"}
{"@timestamp": "2026-01-17T05:00:02.345Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 981, "message": "--- Starting RAG & Knowledge API Service on port 2001 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:09:42.820Z", "log.level": "critical", "log.logger": "neo4j_handler", "log.origin.file.line": 34, "message": "Failed to initialize Neo4j driver: No module named 'neo4j._sync.io._bolt3'", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\neo4j_handler.py\", line 27, in init_driver\n    _neo4j_driver.verify_connectivity()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1007, in verify_connectivity\n    self._get_server_info(session_config)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1218, in _get_server_info\n    return session._get_server_info()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 172, in _get_server_info\n    self._connect(READ_ACCESS, liveness_check_timeout=0)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 130, in _connect\n    super()._connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py\", line 178, in _connect\n    self._connection = self._pool.acquire(**acquire_kwargs_)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 528, in acquire\n    return self._acquire(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 315, in _acquire\n    return connection_creator()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 165, in connection_creator\n    connection = self.opener(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 502, in opener\n    return Bolt.open(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 400, in open\n    BoltSocket.connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 694, in connect\n    return BoltSocket._handshake(s, resolved_address, deadline)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 590, in _handshake\n    handshake = cls.Bolt.get_handshake()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 343, in get_handshake\n    supported_versions = sorted(cls.protocol_handlers().keys(), reverse=True)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 272, in protocol_handlers\n    from ._bolt3 import Bolt3\nModuleNotFoundError: No module named 'neo4j._sync.io._bolt3'"}
{"@timestamp": "2026-01-17T05:10:54.717Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:10:54.894Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:10:54.997Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:10:54.999Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:10:55.817Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:10:55.920Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:10:56.123Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:10:56.124Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:11:05.534Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:11:05.747Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:11:05.851Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:11:05.852Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:11:44.248Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:11:44.354Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:11:44.558Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:11:44.560Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:15:27.620Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:15:27.788Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:15:27.993Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:15:27.995Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:13.007Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:24.186Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:39.942Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:39.965Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:39.968Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:43.330Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:51.261Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 113, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:51.266Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 122, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:51.266Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 27, "message": "Initializing VectorDBService...", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:51.267Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 28, "message": "  Qdrant Host: localhost, Port: 2003, URL: None", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:51.267Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 29, "message": "  Collection: my_qdrant_rag_collection", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:51.267Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 30, "message": "  Query Embedding Model: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:51.267Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 35, "message": "  Service expects Vector Dim for Qdrant collection: 1024 (from document model config)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:51.284Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 54, "message": "  Loading query embedding model: 'mixedbread-ai/mxbai-embed-large-v1'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:51.284Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:57.035Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:57.041Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:57.042Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 57, "message": "  Query model loaded. Output dimension: 1024", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:57.042Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 71, "message": "  Query model output dimension (1024) matches Qdrant collection dimension (1024).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:57.312Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 99, "message": "Collection 'my_qdrant_rag_collection' already exists.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:57.312Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 126, "message": "Collection 'my_qdrant_rag_collection' configuration is compatible (Size: 1024, Distance: Cosine).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:16:57.315Z", "log.level": "critical", "log.logger": "neo4j_handler", "log.origin.file.line": 34, "message": "Failed to initialize Neo4j driver: No module named 'neo4j._sync.io._bolt3'", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\neo4j_handler.py\", line 27, in init_driver\n    _neo4j_driver.verify_connectivity()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1007, in verify_connectivity\n    self._get_server_info(session_config)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1218, in _get_server_info\n    return session._get_server_info()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 172, in _get_server_info\n    self._connect(READ_ACCESS, liveness_check_timeout=0)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 130, in _connect\n    super()._connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py\", line 178, in _connect\n    self._connection = self._pool.acquire(**acquire_kwargs_)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 528, in acquire\n    return self._acquire(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 315, in _acquire\n    return connection_creator()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 165, in connection_creator\n    connection = self.opener(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 502, in opener\n    return Bolt.open(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 400, in open\n    BoltSocket.connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 694, in connect\n    return BoltSocket._handshake(s, resolved_address, deadline)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 590, in _handshake\n    handshake = cls.Bolt.get_handshake()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 343, in get_handshake\n    supported_versions = sorted(cls.protocol_handlers().keys(), reverse=True)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 272, in protocol_handlers\n    from ._bolt3 import Bolt3\nModuleNotFoundError: No module named 'neo4j._sync.io._bolt3'"}
{"@timestamp": "2026-01-17T05:16:57.439Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 981, "message": "--- Starting RAG & Knowledge API Service on port 2001 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:18:45.418Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:18:45.520Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:18:45.725Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:18:45.726Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:20:03.361Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:20:03.528Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:20:03.668Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:20:03.670Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:21:43.490Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:21:43.637Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:21:43.794Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:21:43.795Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:23:16.774Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:23:16.979Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:23:17.077Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:23:17.078Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:23:40.705Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:23:50.808Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:23:59.403Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:23:59.408Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:23:59.410Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:00.537Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:06.378Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 113, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:06.381Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 122, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:06.381Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 27, "message": "Initializing VectorDBService...", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:06.382Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 28, "message": "  Qdrant Host: localhost, Port: 2003, URL: None", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:06.382Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 29, "message": "  Collection: my_qdrant_rag_collection", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:06.382Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 30, "message": "  Query Embedding Model: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:06.382Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 35, "message": "  Service expects Vector Dim for Qdrant collection: 1024 (from document model config)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:06.390Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 54, "message": "  Loading query embedding model: 'mixedbread-ai/mxbai-embed-large-v1'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:06.390Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:13.002Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:13.010Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:13.010Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 57, "message": "  Query model loaded. Output dimension: 1024", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:13.010Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 71, "message": "  Query model output dimension (1024) matches Qdrant collection dimension (1024).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:13.079Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 99, "message": "Collection 'my_qdrant_rag_collection' already exists.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:13.079Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 126, "message": "Collection 'my_qdrant_rag_collection' configuration is compatible (Size: 1024, Distance: Cosine).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:24:13.094Z", "log.level": "critical", "log.logger": "neo4j_handler", "log.origin.file.line": 34, "message": "Failed to initialize Neo4j driver: No module named 'neo4j._sync.io._bolt3'", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\neo4j_handler.py\", line 27, in init_driver\n    _neo4j_driver.verify_connectivity()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1007, in verify_connectivity\n    self._get_server_info(session_config)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1218, in _get_server_info\n    return session._get_server_info()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 172, in _get_server_info\n    self._connect(READ_ACCESS, liveness_check_timeout=0)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 130, in _connect\n    super()._connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py\", line 178, in _connect\n    self._connection = self._pool.acquire(**acquire_kwargs_)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 528, in acquire\n    return self._acquire(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 315, in _acquire\n    return connection_creator()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 165, in connection_creator\n    connection = self.opener(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 502, in opener\n    return Bolt.open(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 400, in open\n    BoltSocket.connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 694, in connect\n    return BoltSocket._handshake(s, resolved_address, deadline)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 590, in _handshake\n    handshake = cls.Bolt.get_handshake()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 343, in get_handshake\n    supported_versions = sorted(cls.protocol_handlers().keys(), reverse=True)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 272, in protocol_handlers\n    from ._bolt3 import Bolt3\nModuleNotFoundError: No module named 'neo4j._sync.io._bolt3'"}
{"@timestamp": "2026-01-17T05:24:13.135Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 981, "message": "--- Starting RAG & Knowledge API Service on port 2001 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:26:55.355Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:26:55.601Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:26:55.908Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:26:55.910Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:27:39.735Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:27:39.837Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:27:40.042Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:27:40.042Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:27:57.761Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:27:57.862Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:27:58.131Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:27:58.132Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:29:34.280Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:29:43.434Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:29:52.256Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:29:52.261Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:29:52.261Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:29:53.483Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:29:59.866Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 113, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:29:59.869Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 122, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:29:59.871Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 27, "message": "Initializing VectorDBService...", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:29:59.871Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 28, "message": "  Qdrant Host: localhost, Port: 2003, URL: None", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:29:59.871Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 29, "message": "  Collection: my_qdrant_rag_collection", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:29:59.872Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 30, "message": "  Query Embedding Model: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:29:59.872Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 35, "message": "  Service expects Vector Dim for Qdrant collection: 1024 (from document model config)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:29:59.885Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 54, "message": "  Loading query embedding model: 'mixedbread-ai/mxbai-embed-large-v1'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:29:59.885Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:30:00.431Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:30:00.636Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:30:00.841Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:30:00.842Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:30:05.361Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:30:05.366Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:30:05.366Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 57, "message": "  Query model loaded. Output dimension: 1024", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:30:05.366Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 71, "message": "  Query model output dimension (1024) matches Qdrant collection dimension (1024).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:30:05.572Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 99, "message": "Collection 'my_qdrant_rag_collection' already exists.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:30:05.572Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 126, "message": "Collection 'my_qdrant_rag_collection' configuration is compatible (Size: 1024, Distance: Cosine).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:30:05.589Z", "log.level": "critical", "log.logger": "neo4j_handler", "log.origin.file.line": 34, "message": "Failed to initialize Neo4j driver: No module named 'neo4j._sync.io._bolt3'", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\neo4j_handler.py\", line 27, in init_driver\n    _neo4j_driver.verify_connectivity()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1007, in verify_connectivity\n    self._get_server_info(session_config)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1218, in _get_server_info\n    return session._get_server_info()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 172, in _get_server_info\n    self._connect(READ_ACCESS, liveness_check_timeout=0)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 130, in _connect\n    super()._connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py\", line 178, in _connect\n    self._connection = self._pool.acquire(**acquire_kwargs_)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 528, in acquire\n    return self._acquire(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 315, in _acquire\n    return connection_creator()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 165, in connection_creator\n    connection = self.opener(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 502, in opener\n    return Bolt.open(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 400, in open\n    BoltSocket.connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 694, in connect\n    return BoltSocket._handshake(s, resolved_address, deadline)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 590, in _handshake\n    handshake = cls.Bolt.get_handshake()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 343, in get_handshake\n    supported_versions = sorted(cls.protocol_handlers().keys(), reverse=True)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 272, in protocol_handlers\n    from ._bolt3 import Bolt3\nModuleNotFoundError: No module named 'neo4j._sync.io._bolt3'"}
{"@timestamp": "2026-01-17T05:30:05.633Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 981, "message": "--- Starting RAG & Knowledge API Service on port 2001 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:31:23.785Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:31:24.473Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:31:24.603Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:31:24.604Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:32:51.307Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:00.453Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:08.332Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:08.338Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:08.339Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:09.393Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:14.216Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 113, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:14.217Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 122, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:14.218Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 27, "message": "Initializing VectorDBService...", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:14.219Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 28, "message": "  Qdrant Host: localhost, Port: 2003, URL: None", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:14.219Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 29, "message": "  Collection: my_qdrant_rag_collection", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:14.219Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 30, "message": "  Query Embedding Model: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:14.220Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 35, "message": "  Service expects Vector Dim for Qdrant collection: 1024 (from document model config)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:14.227Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 54, "message": "  Loading query embedding model: 'mixedbread-ai/mxbai-embed-large-v1'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:14.227Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:18.173Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:18.178Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:18.178Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 57, "message": "  Query model loaded. Output dimension: 1024", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:18.179Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 71, "message": "  Query model output dimension (1024) matches Qdrant collection dimension (1024).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:18.230Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 99, "message": "Collection 'my_qdrant_rag_collection' already exists.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:18.231Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 126, "message": "Collection 'my_qdrant_rag_collection' configuration is compatible (Size: 1024, Distance: Cosine).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:18.233Z", "log.level": "critical", "log.logger": "neo4j_handler", "log.origin.file.line": 34, "message": "Failed to initialize Neo4j driver: No module named 'neo4j._sync.io._bolt3'", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\neo4j_handler.py\", line 27, in init_driver\n    _neo4j_driver.verify_connectivity()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1007, in verify_connectivity\n    self._get_server_info(session_config)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1218, in _get_server_info\n    return session._get_server_info()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 172, in _get_server_info\n    self._connect(READ_ACCESS, liveness_check_timeout=0)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 130, in _connect\n    super()._connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py\", line 178, in _connect\n    self._connection = self._pool.acquire(**acquire_kwargs_)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 528, in acquire\n    return self._acquire(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 315, in _acquire\n    return connection_creator()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 165, in connection_creator\n    connection = self.opener(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 502, in opener\n    return Bolt.open(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 400, in open\n    BoltSocket.connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 694, in connect\n    return BoltSocket._handshake(s, resolved_address, deadline)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 590, in _handshake\n    handshake = cls.Bolt.get_handshake()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 343, in get_handshake\n    supported_versions = sorted(cls.protocol_handlers().keys(), reverse=True)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 272, in protocol_handlers\n    from ._bolt3 import Bolt3\nModuleNotFoundError: No module named 'neo4j._sync.io._bolt3'"}
{"@timestamp": "2026-01-17T05:33:18.273Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 981, "message": "--- Starting RAG & Knowledge API Service on port 2001 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:23.901Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:24.103Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:24.205Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:33:24.207Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:03.071Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:11.654Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:20.668Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:20.672Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:20.673Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:21.923Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:32.812Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:32.916Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:33.120Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:33.120Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:33.777Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 114, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:33.779Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:33.780Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 27, "message": "Initializing VectorDBService...", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:33.780Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 28, "message": "  Qdrant Host: localhost, Port: 2003, URL: None", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:33.780Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 29, "message": "  Collection: my_qdrant_rag_collection", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:33.780Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 30, "message": "  Query Embedding Model: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:33.780Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 35, "message": "  Service expects Vector Dim for Qdrant collection: 1024 (from document model config)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:33.788Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 54, "message": "  Loading query embedding model: 'mixedbread-ai/mxbai-embed-large-v1'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:33.788Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:38.917Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:38.921Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:38.922Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 57, "message": "  Query model loaded. Output dimension: 1024", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:38.922Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 71, "message": "  Query model output dimension (1024) matches Qdrant collection dimension (1024).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:39.153Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 99, "message": "Collection 'my_qdrant_rag_collection' already exists.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:39.153Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 126, "message": "Collection 'my_qdrant_rag_collection' configuration is compatible (Size: 1024, Distance: Cosine).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:34:39.155Z", "log.level": "critical", "log.logger": "neo4j_handler", "log.origin.file.line": 34, "message": "Failed to initialize Neo4j driver: No module named 'neo4j._sync.io._bolt3'", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\neo4j_handler.py\", line 27, in init_driver\n    _neo4j_driver.verify_connectivity()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1007, in verify_connectivity\n    self._get_server_info(session_config)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1218, in _get_server_info\n    return session._get_server_info()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 172, in _get_server_info\n    self._connect(READ_ACCESS, liveness_check_timeout=0)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 130, in _connect\n    super()._connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py\", line 178, in _connect\n    self._connection = self._pool.acquire(**acquire_kwargs_)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 528, in acquire\n    return self._acquire(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 315, in _acquire\n    return connection_creator()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 165, in connection_creator\n    connection = self.opener(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 502, in opener\n    return Bolt.open(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 400, in open\n    BoltSocket.connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 694, in connect\n    return BoltSocket._handshake(s, resolved_address, deadline)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 590, in _handshake\n    handshake = cls.Bolt.get_handshake()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 343, in get_handshake\n    supported_versions = sorted(cls.protocol_handlers().keys(), reverse=True)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 272, in protocol_handlers\n    from ._bolt3 import Bolt3\nModuleNotFoundError: No module named 'neo4j._sync.io._bolt3'"}
{"@timestamp": "2026-01-17T05:34:39.239Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 982, "message": "--- Starting RAG & Knowledge API Service on port 2001 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:10.776Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:19.151Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:26.289Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:26.293Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:26.294Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:27.185Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:31.513Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 114, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:31.514Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:31.515Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 27, "message": "Initializing VectorDBService...", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:31.515Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 28, "message": "  Qdrant Host: localhost, Port: 2003, URL: None", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:31.515Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 29, "message": "  Collection: my_qdrant_rag_collection", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:31.515Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 30, "message": "  Query Embedding Model: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:31.515Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 35, "message": "  Service expects Vector Dim for Qdrant collection: 1024 (from document model config)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:31.522Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 54, "message": "  Loading query embedding model: 'mixedbread-ai/mxbai-embed-large-v1'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:31.523Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:35.191Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:35.195Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:35.195Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 57, "message": "  Query model loaded. Output dimension: 1024", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:35.195Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 71, "message": "  Query model output dimension (1024) matches Qdrant collection dimension (1024).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:35.248Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 99, "message": "Collection 'my_qdrant_rag_collection' already exists.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:35.249Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 126, "message": "Collection 'my_qdrant_rag_collection' configuration is compatible (Size: 1024, Distance: Cosine).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:35.262Z", "log.level": "critical", "log.logger": "neo4j_handler", "log.origin.file.line": 34, "message": "Failed to initialize Neo4j driver: No module named 'neo4j._sync.io._bolt3'", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\neo4j_handler.py\", line 27, in init_driver\n    _neo4j_driver.verify_connectivity()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1007, in verify_connectivity\n    self._get_server_info(session_config)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1218, in _get_server_info\n    return session._get_server_info()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 172, in _get_server_info\n    self._connect(READ_ACCESS, liveness_check_timeout=0)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 130, in _connect\n    super()._connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py\", line 178, in _connect\n    self._connection = self._pool.acquire(**acquire_kwargs_)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 528, in acquire\n    return self._acquire(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 315, in _acquire\n    return connection_creator()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 165, in connection_creator\n    connection = self.opener(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 502, in opener\n    return Bolt.open(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 400, in open\n    BoltSocket.connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 694, in connect\n    return BoltSocket._handshake(s, resolved_address, deadline)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 590, in _handshake\n    handshake = cls.Bolt.get_handshake()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 343, in get_handshake\n    supported_versions = sorted(cls.protocol_handlers().keys(), reverse=True)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 272, in protocol_handlers\n    from ._bolt3 import Bolt3\nModuleNotFoundError: No module named 'neo4j._sync.io._bolt3'"}
{"@timestamp": "2026-01-17T05:36:35.295Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 982, "message": "--- Starting RAG & Knowledge API Service on port 2001 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:36.921Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:37.023Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:37.201Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:36:37.203Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 150, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:28.293Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:33.644Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:39.626Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:39.629Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:39.631Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:40.771Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:45.091Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 114, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:45.093Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:45.094Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 27, "message": "Initializing VectorDBService...", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:45.094Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 28, "message": "  Qdrant Host: localhost, Port: 2003, URL: None", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:45.094Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 29, "message": "  Collection: my_qdrant_rag_collection", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:45.094Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 30, "message": "  Query Embedding Model: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:45.094Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 35, "message": "  Service expects Vector Dim for Qdrant collection: 1024 (from document model config)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:45.104Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 54, "message": "  Loading query embedding model: 'mixedbread-ai/mxbai-embed-large-v1'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:45.104Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:52.042Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:52.049Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:52.050Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 57, "message": "  Query model loaded. Output dimension: 1024", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:52.050Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 71, "message": "  Query model output dimension (1024) matches Qdrant collection dimension (1024).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:52.132Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 99, "message": "Collection 'my_qdrant_rag_collection' already exists.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:52.133Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 126, "message": "Collection 'my_qdrant_rag_collection' configuration is compatible (Size: 1024, Distance: Cosine).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:52.135Z", "log.level": "critical", "log.logger": "neo4j_handler", "log.origin.file.line": 34, "message": "Failed to initialize Neo4j driver: No module named 'neo4j._sync.io._bolt3'", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\neo4j_handler.py\", line 27, in init_driver\n    _neo4j_driver.verify_connectivity()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1007, in verify_connectivity\n    self._get_server_info(session_config)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1218, in _get_server_info\n    return session._get_server_info()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 172, in _get_server_info\n    self._connect(READ_ACCESS, liveness_check_timeout=0)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 130, in _connect\n    super()._connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py\", line 178, in _connect\n    self._connection = self._pool.acquire(**acquire_kwargs_)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 528, in acquire\n    return self._acquire(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 315, in _acquire\n    return connection_creator()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 165, in connection_creator\n    connection = self.opener(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 502, in opener\n    return Bolt.open(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 400, in open\n    BoltSocket.connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 694, in connect\n    return BoltSocket._handshake(s, resolved_address, deadline)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 590, in _handshake\n    handshake = cls.Bolt.get_handshake()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 343, in get_handshake\n    supported_versions = sorted(cls.protocol_handlers().keys(), reverse=True)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 272, in protocol_handlers\n    from ._bolt3 import Bolt3\nModuleNotFoundError: No module named 'neo4j._sync.io._bolt3'"}
{"@timestamp": "2026-01-17T05:37:52.162Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 982, "message": "--- Starting RAG & Knowledge API Service on port 2001 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:54.928Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:55.051Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:55.256Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:37:55.256Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 150, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:24.589Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:32.618Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:39.535Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:39.554Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:39.556Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:40.417Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:44.582Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 114, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:44.584Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:44.585Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 27, "message": "Initializing VectorDBService...", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:44.585Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 28, "message": "  Qdrant Host: localhost, Port: 2003, URL: None", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:44.586Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 29, "message": "  Collection: my_qdrant_rag_collection", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:44.586Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 30, "message": "  Query Embedding Model: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:44.586Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 35, "message": "  Service expects Vector Dim for Qdrant collection: 1024 (from document model config)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:44.596Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 54, "message": "  Loading query embedding model: 'mixedbread-ai/mxbai-embed-large-v1'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:44.597Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:48.621Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:48.625Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:48.625Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 57, "message": "  Query model loaded. Output dimension: 1024", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:48.626Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 71, "message": "  Query model output dimension (1024) matches Qdrant collection dimension (1024).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:48.669Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 99, "message": "Collection 'my_qdrant_rag_collection' already exists.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:48.669Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 126, "message": "Collection 'my_qdrant_rag_collection' configuration is compatible (Size: 1024, Distance: Cosine).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:48.672Z", "log.level": "critical", "log.logger": "neo4j_handler", "log.origin.file.line": 34, "message": "Failed to initialize Neo4j driver: No module named 'neo4j._sync.io._bolt3'", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\neo4j_handler.py\", line 27, in init_driver\n    _neo4j_driver.verify_connectivity()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1007, in verify_connectivity\n    self._get_server_info(session_config)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1218, in _get_server_info\n    return session._get_server_info()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 172, in _get_server_info\n    self._connect(READ_ACCESS, liveness_check_timeout=0)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 130, in _connect\n    super()._connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py\", line 178, in _connect\n    self._connection = self._pool.acquire(**acquire_kwargs_)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 528, in acquire\n    return self._acquire(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 315, in _acquire\n    return connection_creator()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 165, in connection_creator\n    connection = self.opener(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 502, in opener\n    return Bolt.open(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 400, in open\n    BoltSocket.connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 694, in connect\n    return BoltSocket._handshake(s, resolved_address, deadline)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 590, in _handshake\n    handshake = cls.Bolt.get_handshake()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 343, in get_handshake\n    supported_versions = sorted(cls.protocol_handlers().keys(), reverse=True)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 272, in protocol_handlers\n    from ._bolt3 import Bolt3\nModuleNotFoundError: No module named 'neo4j._sync.io._bolt3'"}
{"@timestamp": "2026-01-17T05:38:48.709Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 982, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:56.923Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 1 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 2.014156448s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 2\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:57.108Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 2 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 1.739646643s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 1\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:57.314Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 3 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 1.548920493s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 1\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:38:57.315Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 150, "message": "API Error (500): Socratic chat failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 1.548920493s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 1\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:39:36.850Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:39:42.536Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:39:48.914Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:39:48.918Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:39:48.919Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:39:49.762Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:39:55.608Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 114, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:39:55.610Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:39:55.611Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 27, "message": "Initializing VectorDBService...", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:39:55.611Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 28, "message": "  Qdrant Host: localhost, Port: 2003, URL: None", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:39:55.611Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 29, "message": "  Collection: my_qdrant_rag_collection", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:39:55.611Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 30, "message": "  Query Embedding Model: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:39:55.611Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 35, "message": "  Service expects Vector Dim for Qdrant collection: 1024 (from document model config)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:39:55.622Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 54, "message": "  Loading query embedding model: 'mixedbread-ai/mxbai-embed-large-v1'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:39:55.622Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:40:08.036Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:40:08.044Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:40:08.044Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 57, "message": "  Query model loaded. Output dimension: 1024", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:40:08.044Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 71, "message": "  Query model output dimension (1024) matches Qdrant collection dimension (1024).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:40:08.128Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 99, "message": "Collection 'my_qdrant_rag_collection' already exists.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:40:08.129Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 126, "message": "Collection 'my_qdrant_rag_collection' configuration is compatible (Size: 1024, Distance: Cosine).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:40:08.134Z", "log.level": "critical", "log.logger": "neo4j_handler", "log.origin.file.line": 34, "message": "Failed to initialize Neo4j driver: No module named 'neo4j._sync.io._bolt3'", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\neo4j_handler.py\", line 27, in init_driver\n    _neo4j_driver.verify_connectivity()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1007, in verify_connectivity\n    self._get_server_info(session_config)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1218, in _get_server_info\n    return session._get_server_info()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 172, in _get_server_info\n    self._connect(READ_ACCESS, liveness_check_timeout=0)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 130, in _connect\n    super()._connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py\", line 178, in _connect\n    self._connection = self._pool.acquire(**acquire_kwargs_)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 528, in acquire\n    return self._acquire(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 315, in _acquire\n    return connection_creator()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 165, in connection_creator\n    connection = self.opener(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 502, in opener\n    return Bolt.open(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 400, in open\n    BoltSocket.connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 694, in connect\n    return BoltSocket._handshake(s, resolved_address, deadline)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 590, in _handshake\n    handshake = cls.Bolt.get_handshake()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 343, in get_handshake\n    supported_versions = sorted(cls.protocol_handlers().keys(), reverse=True)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 272, in protocol_handlers\n    from ._bolt3 import Bolt3\nModuleNotFoundError: No module named 'neo4j._sync.io._bolt3'"}
{"@timestamp": "2026-01-17T05:40:08.169Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 982, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:40:18.839Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 1 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 40.054075815s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 40\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:40:19.024Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 2 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 39.817232902s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 39\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:40:19.127Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 3 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 39.644143786s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 39\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:40:19.128Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 150, "message": "API Error (500): Socratic chat failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 39.644143786s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 39\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:40:50.839Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:00.129Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:09.125Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:09.130Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:09.132Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:10.749Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:22.833Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 114, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:22.835Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:22.836Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 27, "message": "Initializing VectorDBService...", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:22.836Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 28, "message": "  Qdrant Host: localhost, Port: 2003, URL: None", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:22.836Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 29, "message": "  Collection: my_qdrant_rag_collection", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:22.836Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 30, "message": "  Query Embedding Model: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:22.836Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 35, "message": "  Service expects Vector Dim for Qdrant collection: 1024 (from document model config)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:22.850Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 54, "message": "  Loading query embedding model: 'mixedbread-ai/mxbai-embed-large-v1'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:22.850Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:25.177Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 1 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 33.585897261s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 33\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:25.381Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 2 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 33.461799821s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 33\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:25.482Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 3 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 33.29475339s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 33\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:25.483Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 150, "message": "API Error (500): Socratic chat failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 33.29475339s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 33\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:28.396Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:28.401Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:28.402Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 57, "message": "  Query model loaded. Output dimension: 1024", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:28.402Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 71, "message": "  Query model output dimension (1024) matches Qdrant collection dimension (1024).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:28.434Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 99, "message": "Collection 'my_qdrant_rag_collection' already exists.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:28.434Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 126, "message": "Collection 'my_qdrant_rag_collection' configuration is compatible (Size: 1024, Distance: Cosine).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:28.451Z", "log.level": "critical", "log.logger": "neo4j_handler", "log.origin.file.line": 34, "message": "Failed to initialize Neo4j driver: No module named 'neo4j._sync.io._bolt3'", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\neo4j_handler.py\", line 27, in init_driver\n    _neo4j_driver.verify_connectivity()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1007, in verify_connectivity\n    self._get_server_info(session_config)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1218, in _get_server_info\n    return session._get_server_info()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 172, in _get_server_info\n    self._connect(READ_ACCESS, liveness_check_timeout=0)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 130, in _connect\n    super()._connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py\", line 178, in _connect\n    self._connection = self._pool.acquire(**acquire_kwargs_)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 528, in acquire\n    return self._acquire(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 315, in _acquire\n    return connection_creator()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 165, in connection_creator\n    connection = self.opener(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 502, in opener\n    return Bolt.open(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 400, in open\n    BoltSocket.connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 694, in connect\n    return BoltSocket._handshake(s, resolved_address, deadline)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 590, in _handshake\n    handshake = cls.Bolt.get_handshake()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 343, in get_handshake\n    supported_versions = sorted(cls.protocol_handlers().keys(), reverse=True)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 272, in protocol_handlers\n    from ._bolt3 import Bolt3\nModuleNotFoundError: No module named 'neo4j._sync.io._bolt3'"}
{"@timestamp": "2026-01-17T05:41:28.483Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 982, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:43.402Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 1 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 15.403659723s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 15\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:43.505Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 2 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 15.260429128s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 15\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:43.709Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 3 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 15.098332476s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 15\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:41:43.710Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 150, "message": "API Error (500): Socratic chat failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 15.098332476s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 15\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:05.719Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:12.987Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:20.590Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:20.594Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:20.594Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:21.388Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:29.424Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 114, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:29.428Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:29.429Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 27, "message": "Initializing VectorDBService...", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:29.429Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 28, "message": "  Qdrant Host: localhost, Port: 2003, URL: None", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:29.429Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 29, "message": "  Collection: my_qdrant_rag_collection", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:29.429Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 30, "message": "  Query Embedding Model: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:29.430Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 35, "message": "  Service expects Vector Dim for Qdrant collection: 1024 (from document model config)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:29.440Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 54, "message": "  Loading query embedding model: 'mixedbread-ai/mxbai-embed-large-v1'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:29.441Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:36.022Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:36.027Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:36.028Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 57, "message": "  Query model loaded. Output dimension: 1024", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:36.028Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 71, "message": "  Query model output dimension (1024) matches Qdrant collection dimension (1024).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:36.082Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 99, "message": "Collection 'my_qdrant_rag_collection' already exists.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:36.083Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 126, "message": "Collection 'my_qdrant_rag_collection' configuration is compatible (Size: 1024, Distance: Cosine).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:36.098Z", "log.level": "critical", "log.logger": "neo4j_handler", "log.origin.file.line": 34, "message": "Failed to initialize Neo4j driver: No module named 'neo4j._sync.io._bolt3'", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\neo4j_handler.py\", line 27, in init_driver\n    _neo4j_driver.verify_connectivity()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1007, in verify_connectivity\n    self._get_server_info(session_config)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1218, in _get_server_info\n    return session._get_server_info()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 172, in _get_server_info\n    self._connect(READ_ACCESS, liveness_check_timeout=0)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 130, in _connect\n    super()._connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py\", line 178, in _connect\n    self._connection = self._pool.acquire(**acquire_kwargs_)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 528, in acquire\n    return self._acquire(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 315, in _acquire\n    return connection_creator()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 165, in connection_creator\n    connection = self.opener(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 502, in opener\n    return Bolt.open(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 400, in open\n    BoltSocket.connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 694, in connect\n    return BoltSocket._handshake(s, resolved_address, deadline)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 590, in _handshake\n    handshake = cls.Bolt.get_handshake()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 343, in get_handshake\n    supported_versions = sorted(cls.protocol_handlers().keys(), reverse=True)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 272, in protocol_handlers\n    from ._bolt3 import Bolt3\nModuleNotFoundError: No module named 'neo4j._sync.io._bolt3'"}
{"@timestamp": "2026-01-17T05:42:36.133Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 982, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:36.447Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 1 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 22.313822952s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 22\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:36.647Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 2 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 22.217367416s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 22\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:36.750Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 3 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 22.012271337s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 22\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:36.750Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 150, "message": "API Error (500): Socratic chat failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 22.012271337s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 22\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:56.141Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 1 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 2.677037548s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 2\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:56.309Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 2 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 2.521960767s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 2\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:56.428Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 3 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 2.348276142s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 2\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:42:56.430Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 150, "message": "API Error (500): Socratic chat failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 2.348276142s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 2\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:43:18.092Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 1 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 40.686677407s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 40\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:43:18.223Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 2 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 40.561428986s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 40\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:43:18.381Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 3 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 40.38170332s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 40\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:43:18.399Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 150, "message": "API Error (500): Socratic chat failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 40.38170332s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 40\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:21.361Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:30.436Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:37.593Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:37.597Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:37.598Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:38.403Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:44.772Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 114, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:44.774Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:44.774Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 27, "message": "Initializing VectorDBService...", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:44.774Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 28, "message": "  Qdrant Host: localhost, Port: 2003, URL: None", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:44.774Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 29, "message": "  Collection: my_qdrant_rag_collection", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:44.775Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 30, "message": "  Query Embedding Model: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:44.775Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 35, "message": "  Service expects Vector Dim for Qdrant collection: 1024 (from document model config)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:44.786Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 54, "message": "  Loading query embedding model: 'mixedbread-ai/mxbai-embed-large-v1'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:44.786Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:58.176Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:58.179Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:58.179Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 57, "message": "  Query model loaded. Output dimension: 1024", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:58.179Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 71, "message": "  Query model output dimension (1024) matches Qdrant collection dimension (1024).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:58.250Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 99, "message": "Collection 'my_qdrant_rag_collection' already exists.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:58.250Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 126, "message": "Collection 'my_qdrant_rag_collection' configuration is compatible (Size: 1024, Distance: Cosine).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:44:58.265Z", "log.level": "critical", "log.logger": "neo4j_handler", "log.origin.file.line": 34, "message": "Failed to initialize Neo4j driver: No module named 'neo4j._sync.io._bolt3'", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\neo4j_handler.py\", line 27, in init_driver\n    _neo4j_driver.verify_connectivity()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1007, in verify_connectivity\n    self._get_server_info(session_config)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1218, in _get_server_info\n    return session._get_server_info()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 172, in _get_server_info\n    self._connect(READ_ACCESS, liveness_check_timeout=0)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 130, in _connect\n    super()._connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py\", line 178, in _connect\n    self._connection = self._pool.acquire(**acquire_kwargs_)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 528, in acquire\n    return self._acquire(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 315, in _acquire\n    return connection_creator()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 165, in connection_creator\n    connection = self.opener(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 502, in opener\n    return Bolt.open(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 400, in open\n    BoltSocket.connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 694, in connect\n    return BoltSocket._handshake(s, resolved_address, deadline)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 590, in _handshake\n    handshake = cls.Bolt.get_handshake()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 343, in get_handshake\n    supported_versions = sorted(cls.protocol_handlers().keys(), reverse=True)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 272, in protocol_handlers\n    from ._bolt3 import Bolt3\nModuleNotFoundError: No module named 'neo4j._sync.io._bolt3'"}
{"@timestamp": "2026-01-17T05:44:58.299Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 982, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:00.667Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 1 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 58.133218666s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 58\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:00.827Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 2 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 57.978190869s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 57\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:00.943Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 3 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 57.814244975s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 57\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:00.943Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 150, "message": "API Error (500): Socratic chat failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 57.814244975s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 57\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:31.757Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:39.494Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:46.938Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:46.941Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:46.942Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:48.332Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:54.841Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 113, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:54.844Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 122, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:54.845Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 27, "message": "Initializing VectorDBService...", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:54.845Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 28, "message": "  Qdrant Host: localhost, Port: 2003, URL: None", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:54.845Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 29, "message": "  Collection: my_qdrant_rag_collection", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:54.845Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 30, "message": "  Query Embedding Model: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:54.845Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 35, "message": "  Service expects Vector Dim for Qdrant collection: 1024 (from document model config)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:54.858Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 54, "message": "  Loading query embedding model: 'mixedbread-ai/mxbai-embed-large-v1'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:54.858Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:58.470Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 1 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 330.85412ms. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:58.694Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 2 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 147.806715ms. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:58.832Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 3 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 59.951315722s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 59\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:58.833Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 150, "message": "API Error (500): Socratic chat failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 59.951315722s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 59\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:59.176Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:59.180Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:59.181Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 57, "message": "  Query model loaded. Output dimension: 1024", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:59.181Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 71, "message": "  Query model output dimension (1024) matches Qdrant collection dimension (1024).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:59.217Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 99, "message": "Collection 'my_qdrant_rag_collection' already exists.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:59.217Z", "log.level": "info", "log.logger": "vector_db_service", "log.origin.file.line": 126, "message": "Collection 'my_qdrant_rag_collection' configuration is compatible (Size: 1024, Distance: Cosine).", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-17T05:45:59.220Z", "log.level": "critical", "log.logger": "neo4j_handler", "log.origin.file.line": 34, "message": "Failed to initialize Neo4j driver: No module named 'neo4j._sync.io._bolt3'", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\neo4j_handler.py\", line 27, in init_driver\n    _neo4j_driver.verify_connectivity()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1007, in verify_connectivity\n    self._get_server_info(session_config)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\driver.py\", line 1218, in _get_server_info\n    return session._get_server_info()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 172, in _get_server_info\n    self._connect(READ_ACCESS, liveness_check_timeout=0)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 130, in _connect\n    super()._connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py\", line 178, in _connect\n    self._connection = self._pool.acquire(**acquire_kwargs_)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 528, in acquire\n    return self._acquire(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 315, in _acquire\n    return connection_creator()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 165, in connection_creator\n    connection = self.opener(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py\", line 502, in opener\n    return Bolt.open(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 400, in open\n    BoltSocket.connect(\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 694, in connect\n    return BoltSocket._handshake(s, resolved_address, deadline)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py\", line 590, in _handshake\n    handshake = cls.Bolt.get_handshake()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 343, in get_handshake\n    supported_versions = sorted(cls.protocol_handlers().keys(), reverse=True)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 272, in protocol_handlers\n    from ._bolt3 import Bolt3\nModuleNotFoundError: No module named 'neo4j._sync.io._bolt3'"}
{"@timestamp": "2026-01-17T05:45:59.313Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 981, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:17:34.547Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:17:34.556Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 238, "message": "Failed to load SpaCy model 'en_core_web_sm': No module named 'spacy'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:17:34.557Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 246, "message": "Failed to load Sentence Transformer model 'mixedbread-ai/mxbai-embed-large-v1': No module named 'sentence_transformers'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:17:34.557Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:17:34.558Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:17:36.738Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 113, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:17:36.756Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 122, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:17:36.762Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 981, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:18:01.997Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:18:02.203Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:18:02.304Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:18:02.304Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:27:51.676Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:27:51.683Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 238, "message": "Failed to load SpaCy model 'en_core_web_sm': No module named 'spacy'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:27:51.684Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 246, "message": "Failed to load Sentence Transformer model 'mixedbread-ai/mxbai-embed-large-v1': No module named 'sentence_transformers'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:27:51.684Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:27:51.685Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:27:52.555Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 113, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:27:52.557Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 122, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:27:52.562Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 981, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:28:06.766Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 1 failed: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:28:06.859Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 2 failed: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:28:07.073Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 89, "message": "LLM generation attempt 3 failed: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:28:07.074Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 149, "message": "API Error (500): Socratic chat failed: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:29:34.880Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:29:34.885Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 238, "message": "Failed to load SpaCy model 'en_core_web_sm': No module named 'spacy'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:29:34.886Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 246, "message": "Failed to load Sentence Transformer model 'mixedbread-ai/mxbai-embed-large-v1': No module named 'sentence_transformers'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:29:34.886Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:29:34.887Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:29:35.759Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 114, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:29:35.760Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:29:35.767Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 982, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:29:53.365Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 1 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 6.193949657s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 6\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:29:53.470Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 2 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 5.979680659s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 5\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:29:53.773Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 3 failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 5.788098855s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 5\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:29:53.774Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 150, "message": "API Error (500): Socratic chat failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 5.788098855s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 5\n}\n]", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:30:49.880Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:30:49.888Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 238, "message": "Failed to load SpaCy model 'en_core_web_sm': No module named 'spacy'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:30:49.888Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 246, "message": "Failed to load Sentence Transformer model 'mixedbread-ai/mxbai-embed-large-v1': No module named 'sentence_transformers'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:30:49.889Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:30:49.890Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:30:50.917Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 114, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:30:50.919Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:30:50.924Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 982, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:31:03.303Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:31:03.506Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:31:03.609Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 90, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:31:03.610Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 150, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:31:50.467Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:31:50.475Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 238, "message": "Failed to load SpaCy model 'en_core_web_sm': No module named 'spacy'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:31:50.475Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 246, "message": "Failed to load Sentence Transformer model 'mixedbread-ai/mxbai-embed-large-v1': No module named 'sentence_transformers'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:31:50.476Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:31:50.476Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:31:51.419Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 114, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:31:51.422Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:31:51.427Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 982, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:32:59.413Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:32:59.420Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 238, "message": "Failed to load SpaCy model 'en_core_web_sm': No module named 'spacy'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:32:59.421Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 246, "message": "Failed to load Sentence Transformer model 'mixedbread-ai/mxbai-embed-large-v1': No module named 'sentence_transformers'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:32:59.421Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:32:59.422Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:33:00.330Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 113, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:33:00.332Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 122, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:33:00.336Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 981, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:34:00.865Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:34:00.872Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 238, "message": "Failed to load SpaCy model 'en_core_web_sm': No module named 'spacy'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:34:00.872Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 246, "message": "Failed to load Sentence Transformer model 'mixedbread-ai/mxbai-embed-large-v1': No module named 'sentence_transformers'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:34:00.873Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:34:00.874Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:34:02.021Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 113, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:34:02.025Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 122, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:34:02.040Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 981, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:38:40.720Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:38:49.479Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:38:57.137Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:38:57.150Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:38:57.152Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:38:57.154Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:39:02.226Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 113, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:39:02.228Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 122, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:39:02.232Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 981, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T04:41:32.086Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 875, "message": "Exception on /health [GET]", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n    response = self.full_dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n    rv = self.dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\app.py\", line 504, in health_check\n    neo4j_ok, neo4j_conn_status = neo4j_handler.check_neo4j_connectivity()\nNameError: name 'neo4j_handler' is not defined"}
{"@timestamp": "2026-01-18T04:42:57.461Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 875, "message": "Exception on /health [GET]", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n    response = self.full_dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n    rv = self.dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\app.py\", line 504, in health_check\n    neo4j_ok, neo4j_conn_status = neo4j_handler.check_neo4j_connectivity()\nNameError: name 'neo4j_handler' is not defined"}
{"@timestamp": "2026-01-18T04:58:22.818Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 875, "message": "Exception on /health [GET]", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n    response = self.full_dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n    rv = self.dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\app.py\", line 504, in health_check\n    neo4j_ok, neo4j_conn_status = neo4j_handler.check_neo4j_connectivity()\nNameError: name 'neo4j_handler' is not defined"}
{"@timestamp": "2026-01-18T05:05:25.060Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 875, "message": "Exception on /health [GET]", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n    response = self.full_dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n    rv = self.dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\app.py\", line 504, in health_check\n    neo4j_ok, neo4j_conn_status = neo4j_handler.check_neo4j_connectivity()\nNameError: name 'neo4j_handler' is not defined"}
{"@timestamp": "2026-01-18T05:19:40.588Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:19:40.594Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 238, "message": "Failed to load SpaCy model 'en_core_web_sm': No module named 'spacy'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:19:40.595Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 246, "message": "Failed to load Sentence Transformer model 'mixedbread-ai/mxbai-embed-large-v1': No module named 'sentence_transformers'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:19:40.595Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:19:40.597Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:19:42.118Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 113, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:19:42.120Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 122, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:19:42.126Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 989, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:20:58.904Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:20:58.911Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 238, "message": "Failed to load SpaCy model 'en_core_web_sm': No module named 'spacy'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:20:58.912Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 246, "message": "Failed to load Sentence Transformer model 'mixedbread-ai/mxbai-embed-large-v1': No module named 'sentence_transformers'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:20:58.912Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:20:58.913Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:20:59.829Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:20:59.830Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 132, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:20:59.836Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 999, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:28:32.654Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 875, "message": "Exception on /health [GET]", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n    response = self.full_dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n    rv = self.dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\app.py\", line 522, in health_check\n    neo4j_ok, neo4j_conn_status = neo4j_handler.check_neo4j_connectivity()\nNameError: name 'neo4j_handler' is not defined"}
{"@timestamp": "2026-01-18T05:28:59.345Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 98, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:29:00.567Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 98, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:29:01.796Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 98, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:29:02.923Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 98, "message": "LLM generation attempt 4 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:29:04.048Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 98, "message": "LLM generation attempt 5 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:29:04.049Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 159, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:35:46.225Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:35:46.232Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 238, "message": "Failed to load SpaCy model 'en_core_web_sm': No module named 'spacy'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:35:46.232Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 246, "message": "Failed to load Sentence Transformer model 'mixedbread-ai/mxbai-embed-large-v1': No module named 'sentence_transformers'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:35:46.233Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:35:46.233Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:35:47.257Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:35:47.259Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 132, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:35:47.265Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 999, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:36:14.337Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 875, "message": "Exception on /health [GET]", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n    response = self.full_dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n    rv = self.dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\app.py\", line 522, in health_check\n    neo4j_ok, neo4j_conn_status = neo4j_handler.check_neo4j_connectivity()\nNameError: name 'neo4j_handler' is not defined"}
{"@timestamp": "2026-01-18T05:41:14.277Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 1.54s... (Attempt 1/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:41:15.996Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 2.37s... (Attempt 2/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:41:18.513Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 4.79s... (Attempt 3/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:41:23.473Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 8.00s... (Attempt 4/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:41:31.574Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 16.06s... (Attempt 5/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:41:55.420Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 1.09s... (Attempt 1/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:41:56.649Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 2.14s... (Attempt 2/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:41:58.907Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 4.19s... (Attempt 3/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:42:03.307Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 8.95s... (Attempt 4/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:42:12.419Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 16.98s... (Attempt 5/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:45:38.806Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:45:38.811Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 238, "message": "Failed to load SpaCy model 'en_core_web_sm': No module named 'spacy'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:45:38.812Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 246, "message": "Failed to load Sentence Transformer model 'mixedbread-ai/mxbai-embed-large-v1': No module named 'sentence_transformers'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:45:38.812Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:45:38.813Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:45:39.799Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:45:39.801Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 132, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:45:39.807Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 999, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:46:00.092Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 875, "message": "Exception on /health [GET]", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n    response = self.full_dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n    rv = self.dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\app.py\", line 522, in health_check\n    neo4j_ok, neo4j_conn_status = neo4j_handler.check_neo4j_connectivity()\nNameError: name 'neo4j_handler' is not defined"}
{"@timestamp": "2026-01-18T05:46:18.075Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 1.71s... (Attempt 1/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:46:20.224Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 2.29s... (Attempt 2/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:46:22.990Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 4.08s... (Attempt 3/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:46:27.490Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 8.64s... (Attempt 4/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:46:36.610Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 16.23s... (Attempt 5/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:52:05.719Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 1.75s... (Attempt 1/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:52:07.869Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 2.25s... (Attempt 2/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:52:10.502Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 4.41s... (Attempt 3/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:52:15.344Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 8.98s... (Attempt 4/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:52:24.763Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 16.16s... (Attempt 5/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:54:03.069Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 1.23s... (Attempt 1/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:54:04.688Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 2.32s... (Attempt 2/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:54:07.346Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 4.66s... (Attempt 3/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:54:12.387Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 8.59s... (Attempt 4/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:54:21.398Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 16.67s... (Attempt 5/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:55:54.701Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:55:54.706Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 238, "message": "Failed to load SpaCy model 'en_core_web_sm': No module named 'spacy'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:55:54.706Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 246, "message": "Failed to load Sentence Transformer model 'mixedbread-ai/mxbai-embed-large-v1': No module named 'sentence_transformers'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:55:54.707Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:55:54.708Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:55:55.601Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:55:55.603Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 132, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:55:55.608Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 999, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:56:18.515Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 875, "message": "Exception on /health [GET]", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n    response = self.full_dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n    rv = self.dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\app.py\", line 522, in health_check\n    neo4j_ok, neo4j_conn_status = neo4j_handler.check_neo4j_connectivity()\nNameError: name 'neo4j_handler' is not defined"}
{"@timestamp": "2026-01-18T05:56:39.126Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 1.96s... (Attempt 1/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:56:41.186Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 2.72s... (Attempt 2/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:56:44.040Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 4.75s... (Attempt 3/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:56:48.956Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 8.73s... (Attempt 4/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:56:57.800Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 16.27s... (Attempt 5/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:58:03.037Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:58:03.043Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 238, "message": "Failed to load SpaCy model 'en_core_web_sm': No module named 'spacy'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:58:03.044Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 246, "message": "Failed to load Sentence Transformer model 'mixedbread-ai/mxbai-embed-large-v1': No module named 'sentence_transformers'", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:58:03.045Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:58:03.046Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:58:03.919Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:58:03.920Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 132, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:58:03.925Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 999, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T05:58:42.657Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 875, "message": "Exception on /health [GET]", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n    response = self.full_dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n    rv = self.dispatch_request()\n  File \"C:\\Users\\gopi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\app.py\", line 522, in health_check\n    neo4j_ok, neo4j_conn_status = neo4j_handler.check_neo4j_connectivity()\nNameError: name 'neo4j_handler' is not defined"}
{"@timestamp": "2026-01-18T06:01:36.493Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 1.58s... (Attempt 1/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T06:01:38.436Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 2.49s... (Attempt 2/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T06:01:41.304Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 4.29s... (Attempt 3/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T06:01:45.975Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 8.41s... (Attempt 4/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T06:01:54.821Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 16.39s... (Attempt 5/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:02:02.609Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:02:10.291Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:02:18.449Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:02:18.456Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:02:18.459Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:02:18.461Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:02:22.740Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:02:22.743Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 132, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:02:22.750Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 999, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:04:33.421Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:04:41.366Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:04:48.478Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:04:48.482Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:04:48.483Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:04:48.484Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:04:51.077Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:04:51.079Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 132, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:04:51.085Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 999, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:05:34.226Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 98, "message": "LLM generation attempt 1 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:05:35.337Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 98, "message": "LLM generation attempt 2 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:05:36.457Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 98, "message": "LLM generation attempt 3 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:05:37.665Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 98, "message": "LLM generation attempt 4 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:05:38.815Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 98, "message": "LLM generation attempt 5 failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:05:38.815Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 159, "message": "API Error (500): Socratic chat failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:08:08.741Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:08:14.858Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:08:21.031Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:08:21.037Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:08:21.038Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:08:21.040Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:08:23.916Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:08:23.918Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 132, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:08:23.924Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 999, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:10:50.496Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 1.52s... (Attempt 1/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:10:52.164Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 2.35s... (Attempt 2/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:10:54.645Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 4.02s... (Attempt 3/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:10:58.799Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 8.98s... (Attempt 4/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:11:07.921Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 16.91s... (Attempt 5/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:12:19.151Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 1.79s... (Attempt 1/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:12:21.142Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 2.25s... (Attempt 2/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:12:23.509Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 4.08s... (Attempt 3/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:12:27.704Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 8.19s... (Attempt 4/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:12:36.092Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 16.72s... (Attempt 5/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:14:11.018Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 1.92s... (Attempt 1/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:14:13.063Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 2.47s... (Attempt 2/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:14:15.664Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 4.77s... (Attempt 3/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:14:20.641Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 8.63s... (Attempt 4/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:14:29.448Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 16.57s... (Attempt 5/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:14:46.548Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 1.08s... (Attempt 1/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:14:47.879Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 2.01s... (Attempt 2/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:14:50.013Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 4.21s... (Attempt 3/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:14:54.431Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 8.91s... (Attempt 4/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:15:03.478Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 16.55s... (Attempt 5/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:15:20.351Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 1.07s... (Attempt 1/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:15:21.568Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 2.68s... (Attempt 2/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:15:24.435Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 4.78s... (Attempt 3/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:15:29.351Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 8.72s... (Attempt 4/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:15:38.259Z", "log.level": "warning", "log.logger": "__main__", "log.origin.file.line": 95, "message": "LLM Rate Limit Hit (429). Retrying in 16.73s... (Attempt 5/5)", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:23:01.606Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:23:07.642Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:23:14.393Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:23:14.398Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:23:14.399Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:23:14.400Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:23:16.824Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 123, "message": "Sentry initialized successfully for Python RAG service.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:23:16.828Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 132, "message": "Prometheus metrics endpoint initialized at /metrics.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:23:16.833Z", "log.level": "info", "log.logger": "__main__", "log.origin.file.line": 999, "message": "--- Starting RAG & Knowledge API Service on port 2002 ---", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T11:23:17.381Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 1414, "message": "Exception on /health [GET]", "service.name": "ai-tutor-python-rag", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\flask\\app.py\", line 2190, in wsgi_app\n    response = self.full_dispatch_request()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\flask\\app.py\", line 1486, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\flask\\app.py\", line 1484, in full_dispatch_request\n    rv = self.dispatch_request()\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\venv\\lib\\site-packages\\flask\\app.py\", line 1469, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n  File \"C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\app.py\", line 522, in health_check\n    neo4j_ok, neo4j_conn_status = neo4j_handler.check_neo4j_connectivity()\nNameError: name 'neo4j_handler' is not defined"}
{"@timestamp": "2026-01-18T11:27:19.501Z", "log.level": "error", "log.logger": "app", "log.origin.file.line": 159, "message": "API Error (500): KG ingestion failed: name 'neo4j_handler' is not defined", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T12:49:48.261Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T12:49:52.500Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T12:50:01.831Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T12:50:09.652Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T12:50:09.663Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T12:50:09.664Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T12:50:09.666Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T12:51:23.950Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T12:51:29.984Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 113, "message": "Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T12:51:37.142Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 219, "message": "Use pytorch device_name: cpu", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T12:51:37.149Z", "log.level": "info", "log.logger": "sentence_transformers.SentenceTransformer", "log.origin.file.line": 231, "message": "2 prompts are loaded, with the keys: ['query', 'passage']", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T12:51:37.150Z", "log.level": "warning", "log.logger": "config", "log.origin.file.line": 256, "message": "Failed to pre-load Whisper model: No module named 'whisper'. Transcription will fail.", "service.name": "ai-tutor-python-rag"}
{"@timestamp": "2026-01-18T12:51:37.152Z", "log.level": "info", "log.logger": "config", "log.origin.file.line": 75, "message": "Python logging initialized and standardized. Appending to: C:\\Users\\gopi\\Downloads\\iMentor-Team-2\\iMentor-Team-2\\server\\rag_service\\..\\logs\\python-rag.log", "service.name": "ai-tutor-python-rag"}
